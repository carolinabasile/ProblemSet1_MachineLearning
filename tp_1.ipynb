{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping página 1: <Response [200]>\n",
      "Scraping página 2: <Response [200]>\n",
      "Scraping página 3: <Response [200]>\n",
      "Scraping página 4: <Response [200]>\n",
      "Scraping página 5: <Response [200]>\n",
      "Scraping página 6: <Response [200]>\n",
      "Scraping página 7: <Response [200]>\n",
      "Scraping página 8: <Response [200]>\n",
      "Scraping página 9: <Response [200]>\n",
      "Scraping página 10: <Response [200]>\n",
      "     directorio secuencia_p orden clase dominio mes estrato1 sex age  ...  \\\n",
      "0  1    4514331           1     2     1  BOGOTA   1        2   0  29  ...   \n",
      "1  2    4514331           1     1     1  BOGOTA   1        2   1  36  ...   \n",
      "2  3    4514332           1     4     1  BOGOTA   1        2   1   4  ...   \n",
      "3  4    4514332           1     3     1  BOGOTA   1        2   1   7  ...   \n",
      "4  5    4514332           1     1     1  BOGOTA   1        2   0  32  ...   \n",
      "\n",
      "  y_viaticos_m y_accidentes_m y_salarySec_m y_ingLab_m_ha y_gananciaNeta_m  \\\n",
      "0           NA             NA            NA            NA               NA   \n",
      "1           NA             NA            NA  8404.3203125               NA   \n",
      "2           NA             NA            NA            NA               NA   \n",
      "3           NA             NA            NA            NA               NA   \n",
      "4           NA             NA            NA            NA               NA   \n",
      "\n",
      "  y_gananciaNetaAgro_m y_gananciaIndep_m y_gananciaIndep_m_hu   y_total_m  \\\n",
      "0                   NA                NA                   NA          NA   \n",
      "1                   NA                NA                   NA  1620833.25   \n",
      "2                   NA                NA                   NA          NA   \n",
      "3                   NA                NA                   NA          NA   \n",
      "4                   NA                NA                   NA          NA   \n",
      "\n",
      "   y_total_m_ha  \n",
      "0            NA  \n",
      "1  8404.3203125  \n",
      "2            NA  \n",
      "3            NA  \n",
      "4            NA  \n",
      "\n",
      "[5 rows x 178 columns]\n",
      "Datos guardados en 'geih_data_full.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Armamos una lista para almacenar todos los datos\n",
    "data = []\n",
    "\n",
    "# Base URL de las páginas \n",
    "base_url = 'https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_{}.html'\n",
    "\n",
    "# Iteramos sobre las 10 páginas\n",
    "for i in range(1, 11):  \n",
    "\n",
    "    # Construimos la URL de la página actual\n",
    "    url = base_url.format(i)\n",
    "    \n",
    "    # Enviamos solicitud HTTP\n",
    "    response = requests.get(url)\n",
    "    print(f\"Scraping página {i}: {response}\")  # Confirmar que la solicitud es exitosa (<Response [200]>)\n",
    "    \n",
    "    # Parsear el contenido HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Encontrar la tabla en la página\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    # Extraemos encabezados (solo en la primera iteración)\n",
    "    if i == 1:  # Tomar encabezados solo de la primera página\n",
    "        headers = []\n",
    "        for header in table.find_all('th'):\n",
    "            headers.append(header.text.strip())\n",
    "    \n",
    "    # Extraemos filas de datos\n",
    "    for row in table.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "        if row_data:  # Agregar solo filas con datos\n",
    "            data.append(row_data)\n",
    "\n",
    "# Convertimos los datos consolidados en un DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros después del filtro (empleados mayores de 18 años): 1216\n",
      "Número de registros después de eliminar valores faltantes: 1216\n"
     ]
    }
   ],
   "source": [
    "# Restringimos a individuos empleados mayores de 18 años (HAY QUE REVISAR SI P6240 ES LA CORRECTA)\n",
    "df_limpio = df[(df['age'].astype(float) > 18) & (df['p6240'] == '1')]\n",
    "\n",
    "print(f\"Número de registros después del filtro (empleados mayores de 18 años): {len(df_limpio)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas descriptivas:\n",
      "             directorio secuencia_p orden clase dominio   mes estrato1   sex  \\\n",
      "count   1216       1216        1216  1216  1216    1216  1216     1216  1216   \n",
      "unique  1216        764           4     9     1       1     2        6     2   \n",
      "top        2    4535713           1     1     1  BOGOTA     1        2     1   \n",
      "freq       1          5        1193   612  1216    1216   972      538   693   \n",
      "\n",
      "         age  ... y_viaticos_m y_accidentes_m y_salarySec_m y_ingLab_m_ha  \\\n",
      "count   1216  ...         1216           1216          1216          1216   \n",
      "unique    57  ...           23              3            18           553   \n",
      "top       23  ...           NA             NA            NA            NA   \n",
      "freq      43  ...         1179           1213          1191           447   \n",
      "\n",
      "       y_gananciaNeta_m y_gananciaNetaAgro_m y_gananciaIndep_m  \\\n",
      "count              1216                 1216              1216   \n",
      "unique               60                    1                60   \n",
      "top                  NA                   NA                NA   \n",
      "freq                911                 1216               911   \n",
      "\n",
      "       y_gananciaIndep_m_hu y_total_m y_total_m_ha  \n",
      "count                  1216      1216         1216  \n",
      "unique                  143       466          640  \n",
      "top                      NA        NA           NA  \n",
      "freq                    911       142          142  \n",
      "\n",
      "[4 rows x 178 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df_limpio.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
